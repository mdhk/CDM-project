{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader import CHILDESCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to download the XML version (! important) of the CHILDES corpus\n",
    "# you can access those here (for English, North America): https://childes.talkbank.org/data-xml/Eng-NA/\n",
    "# then you need to unzip it and put it in the 'corpora' folder in your 'nltk_data' folder \n",
    "# (for me, on macOS that's in my user root directory)\n",
    "# and below you tell nltk that it needs to use that folder\n",
    "corpus_root = nltk.data.find('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can use the corpus reader to extract all the dialogues from the Brown corpus\n",
    "brown = CHILDESCorpusReader(corpus_root, 'Brown/.*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown/Adam/020304.xml',\n",
       " 'Brown/Adam/020318.xml',\n",
       " 'Brown/Adam/020403.xml',\n",
       " 'Brown/Adam/020415.xml',\n",
       " 'Brown/Adam/020430.xml',\n",
       " 'Brown/Adam/020512.xml',\n",
       " 'Brown/Adam/020603.xml',\n",
       " 'Brown/Adam/020617.xml',\n",
       " 'Brown/Adam/020701.xml',\n",
       " 'Brown/Adam/020714.xml',\n",
       " 'Brown/Adam/020801.xml',\n",
       " 'Brown/Adam/020816.xml',\n",
       " 'Brown/Adam/020904.xml',\n",
       " 'Brown/Adam/020918.xml',\n",
       " 'Brown/Adam/021002.xml',\n",
       " 'Brown/Adam/021016.xml',\n",
       " 'Brown/Adam/021030.xml',\n",
       " 'Brown/Adam/021113.xml',\n",
       " 'Brown/Adam/021128.xml',\n",
       " 'Brown/Adam/030011.xml',\n",
       " 'Brown/Adam/030025.xml',\n",
       " 'Brown/Adam/030109.xml',\n",
       " 'Brown/Adam/030126.xml',\n",
       " 'Brown/Adam/030209.xml',\n",
       " 'Brown/Adam/030221.xml',\n",
       " 'Brown/Adam/030304.xml',\n",
       " 'Brown/Adam/030318.xml',\n",
       " 'Brown/Adam/030401.xml',\n",
       " 'Brown/Adam/030418.xml',\n",
       " 'Brown/Adam/030501.xml',\n",
       " 'Brown/Adam/030515.xml',\n",
       " 'Brown/Adam/030529.xml',\n",
       " 'Brown/Adam/030609.xml',\n",
       " 'Brown/Adam/030707.xml',\n",
       " 'Brown/Adam/030801.xml',\n",
       " 'Brown/Adam/030814.xml',\n",
       " 'Brown/Adam/030826.xml',\n",
       " 'Brown/Adam/030916.xml',\n",
       " 'Brown/Adam/031015.xml',\n",
       " 'Brown/Adam/031101.xml',\n",
       " 'Brown/Adam/031114.xml',\n",
       " 'Brown/Adam/040014.xml',\n",
       " 'Brown/Adam/040115.xml',\n",
       " 'Brown/Adam/040217.xml',\n",
       " 'Brown/Adam/040309.xml',\n",
       " 'Brown/Adam/040401.xml',\n",
       " 'Brown/Adam/040413.xml',\n",
       " 'Brown/Adam/040511.xml',\n",
       " 'Brown/Adam/040624.xml',\n",
       " 'Brown/Adam/040701.xml',\n",
       " 'Brown/Adam/040729.xml',\n",
       " 'Brown/Adam/040902.xml',\n",
       " 'Brown/Adam/041002.xml',\n",
       " 'Brown/Adam/041023.xml',\n",
       " 'Brown/Adam/050212.xml',\n",
       " 'Brown/Eve/010600a.xml',\n",
       " 'Brown/Eve/010600b.xml',\n",
       " 'Brown/Eve/010700a.xml',\n",
       " 'Brown/Eve/010700b.xml',\n",
       " 'Brown/Eve/010800.xml',\n",
       " 'Brown/Eve/010900a.xml',\n",
       " 'Brown/Eve/010900b.xml',\n",
       " 'Brown/Eve/010900c.xml',\n",
       " 'Brown/Eve/011000a.xml',\n",
       " 'Brown/Eve/011000b.xml',\n",
       " 'Brown/Eve/011100a.xml',\n",
       " 'Brown/Eve/011100b.xml',\n",
       " 'Brown/Eve/020000a.xml',\n",
       " 'Brown/Eve/020000b.xml',\n",
       " 'Brown/Eve/020100a.xml',\n",
       " 'Brown/Eve/020100b.xml',\n",
       " 'Brown/Eve/020200a.xml',\n",
       " 'Brown/Eve/020200b.xml',\n",
       " 'Brown/Eve/020300a.xml',\n",
       " 'Brown/Eve/020300b.xml',\n",
       " 'Brown/Sarah/020305.xml',\n",
       " 'Brown/Sarah/020307.xml',\n",
       " 'Brown/Sarah/020319.xml',\n",
       " 'Brown/Sarah/020322.xml',\n",
       " 'Brown/Sarah/020326.xml',\n",
       " 'Brown/Sarah/020328.xml',\n",
       " 'Brown/Sarah/020410.xml',\n",
       " 'Brown/Sarah/020412.xml',\n",
       " 'Brown/Sarah/020417.xml',\n",
       " 'Brown/Sarah/020419.xml',\n",
       " 'Brown/Sarah/020426.xml',\n",
       " 'Brown/Sarah/020507.xml',\n",
       " 'Brown/Sarah/020515.xml',\n",
       " 'Brown/Sarah/020525.xml',\n",
       " 'Brown/Sarah/020530.xml',\n",
       " 'Brown/Sarah/020604.xml',\n",
       " 'Brown/Sarah/020613.xml',\n",
       " 'Brown/Sarah/020620.xml',\n",
       " 'Brown/Sarah/020630.xml',\n",
       " 'Brown/Sarah/020705.xml',\n",
       " 'Brown/Sarah/020712.xml',\n",
       " 'Brown/Sarah/020718.xml',\n",
       " 'Brown/Sarah/020728.xml',\n",
       " 'Brown/Sarah/020802.xml',\n",
       " 'Brown/Sarah/020825a.xml',\n",
       " 'Brown/Sarah/020825b.xml',\n",
       " 'Brown/Sarah/020900.xml',\n",
       " 'Brown/Sarah/020906.xml',\n",
       " 'Brown/Sarah/020914.xml',\n",
       " 'Brown/Sarah/020920.xml',\n",
       " 'Brown/Sarah/020929.xml',\n",
       " 'Brown/Sarah/021005.xml',\n",
       " 'Brown/Sarah/021011.xml',\n",
       " 'Brown/Sarah/021020.xml',\n",
       " 'Brown/Sarah/021024.xml',\n",
       " 'Brown/Sarah/021102.xml',\n",
       " 'Brown/Sarah/021117.xml',\n",
       " 'Brown/Sarah/021123.xml',\n",
       " 'Brown/Sarah/021130.xml',\n",
       " 'Brown/Sarah/030018a.xml',\n",
       " 'Brown/Sarah/030018b.xml',\n",
       " 'Brown/Sarah/030027.xml',\n",
       " 'Brown/Sarah/030103.xml',\n",
       " 'Brown/Sarah/030110.xml',\n",
       " 'Brown/Sarah/030117.xml',\n",
       " 'Brown/Sarah/030124.xml',\n",
       " 'Brown/Sarah/030202.xml',\n",
       " 'Brown/Sarah/030210.xml',\n",
       " 'Brown/Sarah/030216.xml',\n",
       " 'Brown/Sarah/030223.xml',\n",
       " 'Brown/Sarah/030307a.xml',\n",
       " 'Brown/Sarah/030307b.xml',\n",
       " 'Brown/Sarah/030313.xml',\n",
       " 'Brown/Sarah/030320.xml',\n",
       " 'Brown/Sarah/030328.xml',\n",
       " 'Brown/Sarah/030401.xml',\n",
       " 'Brown/Sarah/030409.xml',\n",
       " 'Brown/Sarah/030416.xml',\n",
       " 'Brown/Sarah/030426.xml',\n",
       " 'Brown/Sarah/030501.xml',\n",
       " 'Brown/Sarah/030507.xml',\n",
       " 'Brown/Sarah/030513.xml',\n",
       " 'Brown/Sarah/030520.xml',\n",
       " 'Brown/Sarah/030606.xml',\n",
       " 'Brown/Sarah/030616.xml',\n",
       " 'Brown/Sarah/030623.xml',\n",
       " 'Brown/Sarah/030630.xml',\n",
       " 'Brown/Sarah/030709.xml',\n",
       " 'Brown/Sarah/030716.xml',\n",
       " 'Brown/Sarah/030723.xml',\n",
       " 'Brown/Sarah/030730.xml',\n",
       " 'Brown/Sarah/030806.xml',\n",
       " 'Brown/Sarah/030812.xml',\n",
       " 'Brown/Sarah/030820.xml',\n",
       " 'Brown/Sarah/030827.xml',\n",
       " 'Brown/Sarah/030903.xml',\n",
       " 'Brown/Sarah/030918.xml',\n",
       " 'Brown/Sarah/030926a.xml',\n",
       " 'Brown/Sarah/030926b.xml',\n",
       " 'Brown/Sarah/031001.xml',\n",
       " 'Brown/Sarah/031009.xml',\n",
       " 'Brown/Sarah/031016.xml',\n",
       " 'Brown/Sarah/031030.xml',\n",
       " 'Brown/Sarah/031109.xml',\n",
       " 'Brown/Sarah/031116.xml',\n",
       " 'Brown/Sarah/031129.xml',\n",
       " 'Brown/Sarah/040005.xml',\n",
       " 'Brown/Sarah/040014.xml',\n",
       " 'Brown/Sarah/040028.xml',\n",
       " 'Brown/Sarah/040104.xml',\n",
       " 'Brown/Sarah/040111.xml',\n",
       " 'Brown/Sarah/040118.xml',\n",
       " 'Brown/Sarah/040128.xml',\n",
       " 'Brown/Sarah/040201.xml',\n",
       " 'Brown/Sarah/040209.xml',\n",
       " 'Brown/Sarah/040216.xml',\n",
       " 'Brown/Sarah/040223.xml',\n",
       " 'Brown/Sarah/040228.xml',\n",
       " 'Brown/Sarah/040307.xml',\n",
       " 'Brown/Sarah/040313.xml',\n",
       " 'Brown/Sarah/040319.xml',\n",
       " 'Brown/Sarah/040326.xml',\n",
       " 'Brown/Sarah/040401.xml',\n",
       " 'Brown/Sarah/040411.xml',\n",
       " 'Brown/Sarah/040418.xml',\n",
       " 'Brown/Sarah/040425.xml',\n",
       " 'Brown/Sarah/040504.xml',\n",
       " 'Brown/Sarah/040508.xml',\n",
       " 'Brown/Sarah/040514.xml',\n",
       " 'Brown/Sarah/040522.xml',\n",
       " 'Brown/Sarah/040529.xml',\n",
       " 'Brown/Sarah/040605.xml',\n",
       " 'Brown/Sarah/040610.xml',\n",
       " 'Brown/Sarah/040617.xml',\n",
       " 'Brown/Sarah/040624.xml',\n",
       " 'Brown/Sarah/040700.xml',\n",
       " 'Brown/Sarah/040711.xml',\n",
       " 'Brown/Sarah/040717.xml',\n",
       " 'Brown/Sarah/040724.xml',\n",
       " 'Brown/Sarah/040807.xml',\n",
       " 'Brown/Sarah/040813.xml',\n",
       " 'Brown/Sarah/040820.xml',\n",
       " 'Brown/Sarah/040904.xml',\n",
       " 'Brown/Sarah/040912.xml',\n",
       " 'Brown/Sarah/040919.xml',\n",
       " 'Brown/Sarah/040926.xml',\n",
       " 'Brown/Sarah/041006.xml',\n",
       " 'Brown/Sarah/041021.xml',\n",
       " 'Brown/Sarah/041027.xml',\n",
       " 'Brown/Sarah/041104.xml',\n",
       " 'Brown/Sarah/041113.xml',\n",
       " 'Brown/Sarah/041119.xml',\n",
       " 'Brown/Sarah/041126.xml',\n",
       " 'Brown/Sarah/050002.xml',\n",
       " 'Brown/Sarah/050010.xml',\n",
       " 'Brown/Sarah/050016.xml',\n",
       " 'Brown/Sarah/050025.xml',\n",
       " 'Brown/Sarah/050030.xml',\n",
       " 'Brown/Sarah/050106.xml']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all the fileids\n",
    "brown.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the corpus and participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CHILDESCorpusReader.corpus of <CHILDESCorpusReader in '/Users/mdhk/nltk_data/corpora'>>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the corpus\n",
    "brown.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the corpus data from the corpus\n",
    "corpus_data = brown.corpus(brown.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActivityType :  toyplay\n",
      "Corpus :  Brown\n",
      "Date :  1962-10-08\n",
      "DesignType :  long\n",
      "GroupType :  TD\n",
      "Lang :  eng\n",
      "PID :  11312/c-00015632-1\n",
      "Version :  2.16.0\n",
      "{http://www.w3.org/2001/XMLSchema-instance}schemaLocation :  http://www.talkbank.org/ns/talkbank https://talkbank.org/software/talkbank.xsd\n"
     ]
    }
   ],
   "source": [
    "# print information for the first dialogue (? not sure) in the corpus\n",
    "for key in sorted(corpus_data[0].keys()):\n",
    "    print(key, \": \", corpus_data[0][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHI :  [('SES', 'MC'), ('age', 'P2Y03M04D'), ('group', 'typical'), ('id', 'CHI'), ('language', 'eng'), ('name', 'Adam'), ('role', 'Target_Child'), ('sex', 'male')]\n",
      "COL :  [('id', 'COL'), ('language', 'eng'), ('name', 'Colin_Fraser'), ('role', 'Investigator')]\n",
      "MOT :  [('id', 'MOT'), ('language', 'eng'), ('role', 'Mother'), ('sex', 'female')]\n",
      "RIC :  [('id', 'RIC'), ('language', 'eng'), ('name', 'Richard_Cromer'), ('role', 'Investigator')]\n",
      "URS :  [('id', 'URS'), ('language', 'eng'), ('name', 'Ursula_Bellugi'), ('role', 'Investigator')]\n"
     ]
    }
   ],
   "source": [
    "# print information about corpus participants (? for a specific dialogue?)\n",
    "corpus_participants = brown.participants(brown.fileids())\n",
    "for this_corpus_participants in corpus_participants[:1]:\n",
    "    for key in sorted(this_corpus_participants.keys()):\n",
    "        dct = this_corpus_participants[key]\n",
    "        print(key, \": \", [(k, dct[k]) for k in sorted(dct.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:\n",
      "ActivityType :  toyplay\n",
      "Corpus :  Brown\n",
      "Date :  1962-10-08\n",
      "DesignType :  long\n",
      "GroupType :  TD\n",
      "Lang :  eng\n",
      "PID :  11312/c-00015632-1\n",
      "Version :  2.16.0\n",
      "{http://www.w3.org/2001/XMLSchema-instance}schemaLocation :  http://www.talkbank.org/ns/talkbank https://talkbank.org/software/talkbank.xsd\n",
      "<class 'nltk.collections.LazyMap'> \n",
      "\n",
      "PARTICIPANTS:\n",
      "CHI :  [('SES', 'MC'), ('age', 'P2Y03M04D'), ('group', 'typical'), ('id', 'CHI'), ('language', 'eng'), ('name', 'Adam'), ('role', 'Target_Child'), ('sex', 'male')]\n",
      "COL :  [('id', 'COL'), ('language', 'eng'), ('name', 'Colin_Fraser'), ('role', 'Investigator')]\n",
      "MOT :  [('id', 'MOT'), ('language', 'eng'), ('role', 'Mother'), ('sex', 'female')]\n",
      "RIC :  [('id', 'RIC'), ('language', 'eng'), ('name', 'Richard_Cromer'), ('role', 'Investigator')]\n",
      "URS :  [('id', 'URS'), ('language', 'eng'), ('name', 'Ursula_Bellugi'), ('role', 'Investigator')]\n",
      "<class 'nltk.collections.LazyMap'> \n",
      "\n",
      "WORDS:\n",
      " ['play', 'checkers', 'big', 'drum', 'big', 'drum', ...] \n",
      " <class 'nltk.collections.LazyConcatenation'>\n",
      "WORDS FROM CHI:\n",
      " ['play', 'checkers', 'big', 'drum', 'big', 'drum', ...] \n",
      " <class 'nltk.collections.LazyConcatenation'>\n",
      "\n",
      "SENTENCES:\n",
      "['play', 'checkers']\n",
      "['big', 'drum']\n",
      "['big', 'drum']\n",
      "['big', 'drum']\n",
      "['big', 'drum']\n",
      "['big', 'drum']\n",
      "['horse']\n",
      "['horse']\n",
      "['who', '']\n",
      "['who', 'is', 'that']\n"
     ]
    }
   ],
   "source": [
    "dialogue_file = 'Brown/Adam/020304.xml'\n",
    "\n",
    "# dialogue info\n",
    "dlg_info = brown.corpus(dialogue_file)\n",
    "print('INFO:')\n",
    "for key in sorted(dlg_info[0].keys()):\n",
    "    print(key, \": \", dlg_info[0][key])\n",
    "print(type(dlg_info), '\\n')\n",
    "\n",
    "# dialogue participants\n",
    "print('PARTICIPANTS:')\n",
    "dlg_partcps = brown.participants(dialogue_file)\n",
    "for this_corpus_participants in dlg_partcps[:1]:\n",
    "    for key in sorted(this_corpus_participants.keys()):\n",
    "        dct = this_corpus_participants[key]\n",
    "        print(key, \": \", [(k, dct[k]) for k in sorted(dct.keys())])\n",
    "print(type(dlg_partcps), '\\n')\n",
    "\n",
    "# individual words\n",
    "dlg_words = brown.words(dialogue_file)\n",
    "print('WORDS:\\n', dlg_words, '\\n', type(dlg_words))\n",
    "\n",
    "# words from a particular speaker\n",
    "dlg_words_CHI = brown.words(dialogue_file, speaker=['CHI'])\n",
    "print('WORDS FROM CHI:\\n', dlg_words_CHI, '\\n', type(dlg_words_CHI))\n",
    "\n",
    "# sentences\n",
    "print('\\nSENTENCES:')\n",
    "for sent in brown.sents(dialogue_file, speaker=['MOT', 'CHI'])[:10]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "We can't get information about what speaker said what sentence (or when each sentence was said), so we can't extract turn-based information.. ugh. Apparently the CHILDES corpus reader just doesn't do this:\n",
    "http://ling-blogs.bu.edu/lx394s19/hw5-childes/\n",
    "\n",
    "> \"Here’s where the CHILDESCorpusReader is most disappointing, I think. We can find the sentences in the corpus from a particular speaker, but we can’t see what other speakers said in between. And if we just look at all the utterances, we can’t tell who is saying which line.\"\n",
    "\n",
    "So we'll need to parse the XML ourselves.. (the link above looks like it has some explanation on it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dialogues through XML\n",
    "Here we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_file = 'Brown/Adam/020304.xml'\n",
    "\n",
    "# get the XML representation\n",
    "brown_xml = brown.xml(dialogue_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.etree.ElementTree.Element'>\n",
      "u0\n",
      "CHI\n",
      "['play', 'checkers']\n",
      "<Element '{http://www.talkbank.org/ns/talkbank}mor' at 0x116302c78>\n"
     ]
    }
   ],
   "source": [
    "# this should find all utterances\n",
    "ns = '{http://www.talkbank.org/ns/talkbank}'\n",
    "utterances = the_xml.findall(ns+'u')\n",
    "\n",
    "# a single utterances\n",
    "utt = utterances[0]\n",
    "print(type(utt))\n",
    "\n",
    "# yay we can see the utterance ID and the speaker\n",
    "print(utt.get('uID'))\n",
    "print(utt.get('who'))\n",
    "\n",
    "# this gets us the words of the utterance\n",
    "print([w.text for w in utt if w.text and w.tag == ns+'w'])\n",
    "\n",
    "# how to access other information? (like pos tags)\n",
    "# not sure, somehow we have to get into the mor \n",
    "# and then the mw and then the pos tag for each word.. (see cell below)\n",
    "for x in utt[0]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw XML for the above"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<u who=\"CHI\" uID=\"u0\">\n",
    "<w>play<mor type=\"mor\"><mw><pos><c>n</c></pos><stem>play</stem></mw><gra type=\"gra\" index=\"1\" head=\"2\" relation=\"MOD\"/></mor></w>\n",
    "<w>checkers<mor type=\"mor\"><mw><pos><c>n</c></pos><stem>checker</stem><mk type=\"sfx\">PL</mk></mw><gra type=\"gra\" index=\"2\" head=\"0\" relation=\"INCROOT\"/></mor></w>\n",
    "<t type=\"p\"><mor type=\"mor\"><mt type=\"p\"/><gra type=\"gra\" index=\"3\" head=\"2\" relation=\"PUNCT\"/></mor></t>\n",
    "\n",
    "<a type=\"extension\" flavor=\"pho\">&lt;1&gt; pe</a>\n",
    "</u>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
